{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Euclidean Distance Vs. Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Programming the distance/similarity metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Euclidean Distance\n",
    "\n",
    "def euclidean_distance(x, y):   \n",
    "    return np.sqrt(np.sum((x - y) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cosine Similarity\n",
    "\n",
    "def cosine_similarity(x, y):\n",
    "    return np.dot(x, y) / (np.sqrt(np.dot(x, x)) * np.sqrt(np.dot(y, y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Calculating Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example array\n",
    "\n",
    "x1 = np.array([1,1])\n",
    "x2 = np.array([3,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.23606797749979"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Euclidean distance between x1 and x2\n",
    "\n",
    "euclidean_distance(x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98058067569092"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cosine Similarity between x1 and x2\n",
    "\n",
    "cosine_similarity(x1, x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### An important example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x3 = x2*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.830951894845301"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Euclidean distance between x1 and x2\n",
    "\n",
    "euclidean_distance(x1, x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98058067569092"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cosine Similarity between x1 and x2\n",
    "\n",
    "cosine_similarity(x1, x3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Effect of Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize functions\n",
    "\n",
    "def l1_normalize(v):\n",
    "    norm = np.sum(np.abs(v))\n",
    "    return v / norm\n",
    "\n",
    "def l2_normalize(v):\n",
    "    norm = np.sqrt(np.sum(np.square(v)))\n",
    "    return v / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing the vectors\n",
    "\n",
    "x11 = l2_normalize(x1)\n",
    "x21 = l2_normalize(x2)\n",
    "x31 = l2_normalize(x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "euclidean_distance(x31, np.array([0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19707523593328433"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Euclidean distance between normalized x1 and x2\n",
    "\n",
    "euclidean_distance(x11, x21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19707523593328433"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Euclidean distance between normalized x1 and x3\n",
    "\n",
    "euclidean_distance(x11, x31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.83205029 0.5547002 ] [0.83205029 0.5547002 ]\n"
     ]
    }
   ],
   "source": [
    "print(x31, x21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9805806756909202"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cosine similarity between normalized x1 and x2\n",
    "\n",
    "cosine_similarity(x11, x31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Collecting some data from Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The required library\n",
    "#!pip install wikipedia\n",
    "import wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['List of deaths due to injuries sustained in boxing',\n",
       " 'Boxer Rebellion',\n",
       " 'Boxing',\n",
       " 'Freddie Roach (boxing)',\n",
       " 'Weight class (boxing)',\n",
       " 'Vijender Singh',\n",
       " 'New England Golden Gloves',\n",
       " 'Knockout Kings (video game)',\n",
       " 'Terry Norris',\n",
       " 'Jeff Mayweather',\n",
       " 'Pernell Whitaker',\n",
       " 'Thammudu (film)',\n",
       " 'Amateur boxing',\n",
       " 'Jerry Quarry',\n",
       " 'Nico Hernandez',\n",
       " 'Heavyweight',\n",
       " 'Katsu!',\n",
       " 'Charles Williams (boxer)',\n",
       " 'Leonard Gardner',\n",
       " 'Leon Spinks']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Data of Pro Boxers\n",
    "result = wikipedia.search(\"Pro Boxers\", results = 20)\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cricket1 = wikipedia.page('Ian Bishop (cricketer)')\n",
    "cricket2 = wikipedia.page('Cricket')\n",
    "cricket3 = wikipedia.page('The cricketers')\n",
    "cricket4 = wikipedia.page('Wisden Cricketers of the Year')\n",
    "cricket5 = wikipedia.page('T. Natarajan')\n",
    "footballer1 = wikipedia.page('Michael Stewart (footballer)')\n",
    "footballer2 = wikipedia.page('Lee Johnson (footballer)')\n",
    "footballer3 = wikipedia.page('College football')\n",
    "footballer4 = wikipedia.page('Maryland Terrapins football')\n",
    "footballer5 = wikipedia.page('Ronaldo')\n",
    "physicist1 = wikipedia.page('Sean M. Carroll')\n",
    "physicist2 = wikipedia.page('Alexander Sergeev (physicist)')\n",
    "physicist3 = wikipedia.page('Theoretical physics')\n",
    "physicist4 = wikipedia.page('J. J. Thomson')\n",
    "physicist5 = wikipedia.page('Arindam Ghosh (physicist)')\n",
    "statistician1 = wikipedia.page('Edward Jones (statistician)')\n",
    "statistician2 = wikipedia.page('Robert Gentleman (statistician)')\n",
    "statistician3 = wikipedia.page('Wayne Smith (statistician)')\n",
    "statistician4 = wikipedia.page('Sherman–Morrison formula')\n",
    "statistician5\n",
    "statistician5 = wikipedia.page('National Statistician')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Proboxer1 = wikipedia.page('Leonard Gardner (boxer)')\n",
    "Proboxer2 = wikipedia.page('Leon Spinks(boxer)')\n",
    "Proboxer3 = wikipedia.page('Vijender Singh(boxer)')\n",
    "Proboxer4 = wikipedia.page('Pernell Whitaker(boxer)')\n",
    "Proboxer5 = wikipedia.page('Jerry Quarry(boxer)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ProMMA1 = wikipedia.page('Al Iaquinta(Pro MMA)')\n",
    "ProMMA2 = wikipedia.page('Bashir Ahmad(Pro MMA)')\n",
    "ProMMA3 = wikipedia.page('Felicia Spencer(Pro MMA)')\n",
    "ProMMA4 = wikipedia.page('Alexander Emelianenko(Pro MMA)')\n",
    "ProMMA5 = wikipedia.page('Ronda Rousey(Pro MMA)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['List of professional MMA training camps',\n",
       " 'Justin Wren',\n",
       " 'Kevin Ferguson Jr.',\n",
       " 'Mixed martial arts',\n",
       " 'Alexander Emelianenko',\n",
       " 'Fatalities in mixed martial arts contests',\n",
       " \"Women's mixed martial arts\",\n",
       " 'Gerald Meerschaert',\n",
       " 'Ronda Rousey',\n",
       " 'Amanda Lucas (fighter)',\n",
       " 'Fallon Fox',\n",
       " 'Sergey Spivak',\n",
       " 'Jason David Frank',\n",
       " 'Felicia Spencer',\n",
       " 'Alain Ngalani',\n",
       " 'Sara McMann',\n",
       " 'Greg Hardy',\n",
       " 'Al Iaquinta',\n",
       " 'Phil Baroni',\n",
       " 'Bashir Ahmad (mixed martial artist)']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Data of Pro MMA\n",
    "result = wikipedia.search(\"Pro MMA\", results = 20) \n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Physicist',\n",
       " 'The Physicists',\n",
       " 'Brian Cox (physicist)',\n",
       " 'Theoretical physics',\n",
       " 'Physicist (album)',\n",
       " 'Albert Einstein',\n",
       " 'Physicist and Christian',\n",
       " 'List of physicists',\n",
       " 'Nuclear physics',\n",
       " 'Medical physicist',\n",
       " 'Chartered Physicist',\n",
       " 'Experimental physics',\n",
       " 'Particle physics',\n",
       " 'Arindam Ghosh (physicist)',\n",
       " 'J. J. Thomson',\n",
       " 'Sean M. Carroll',\n",
       " 'Quantum mechanics',\n",
       " 'William Thomson, 1st Baron Kelvin',\n",
       " 'John Archibald Wheeler',\n",
       " 'Scientist']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Data of physicist\n",
    "result = wikipedia.search(\"physicist\", results = 20) \n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Statistician1 = wikipedia.page('Wayne Smith(Statistician)')\n",
    "Statistician2 = wikipedia.page('James Beckett(Statistician)')\n",
    "Statistician3 = wikipedia.page('Adrian Smith(Statistician)')\n",
    "Statistician4 = wikipedia.page('Edward Jones(Statistician)')\n",
    "Statistician5 = wikipedia.page('Ian Diamond(Statistician)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Statistician',\n",
       " 'James Beckett (statistician)',\n",
       " 'Chartered Statistician',\n",
       " 'Edward Jones (statistician)',\n",
       " 'The American Statistician',\n",
       " 'National Statistical Commission',\n",
       " 'Chief Statistician of Canada',\n",
       " 'National Statistician',\n",
       " 'Wayne Smith (statistician)',\n",
       " 'Law of the unconscious statistician',\n",
       " 'Australian Bureau of Statistics',\n",
       " 'Robert Gentleman (statistician)',\n",
       " 'Government Statistical Service',\n",
       " 'Mathematical statistics',\n",
       " 'Adrian Smith (statistician)',\n",
       " 'Ian Diamond',\n",
       " 'David Cox (statistician)',\n",
       " 'Sherman–Morrison formula',\n",
       " 'First-class cricket',\n",
       " 'Office for National Statistics']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Data of Statistician\n",
    "result = wikipedia.search(\"Statistician\", results = 20) \n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Business acumen',\n",
       " 'Leader of Government Business',\n",
       " 'Asia-Pacific Economic Cooperation',\n",
       " 'Business Leaders for Michigan',\n",
       " 'Arab business leaders',\n",
       " 'FBLA-PBL',\n",
       " 'Thought leader',\n",
       " 'Business Leaders for Sensible Priorities',\n",
       " 'Business partnering',\n",
       " 'Party leaders of the United States Senate',\n",
       " 'Licious',\n",
       " 'Business intelligence',\n",
       " 'International Business Leaders Forum',\n",
       " 'Business oligarch',\n",
       " 'Douglas Pitt',\n",
       " 'Queensland Business Leaders Hall of Fame',\n",
       " 'World Economic Forum',\n",
       " 'The Business Council',\n",
       " 'Marc Benioff',\n",
       " 'Spectacular Smith']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Data of Business Leaders\n",
    "result = wikipedia.search(\"Business Leaders\", results = 20) \n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "BusinessLeaders1 = wikipedia.page('Douglas Pitt(Business Leaders)')\n",
    "BusinessLeaders2 = wikipedia.page('Marc Benioff(Business Leaders)')\n",
    "BusinessLeaders3 = wikipedia.page('Spectacular Smith(Business Leaders)')\n",
    "BusinessLeaders4 = wikipedia.page('FBLA-PBL(Business Leaders)')\n",
    "BusinessLeaders5 = wikipedia.page('Business intelligence(Business Leaders)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the wikipedia pages on machine learning, artificial intelligence, soccer and tennis\n",
    "\n",
    "Box = wikipedia.page(\"Boxers\")\n",
    "BL = wikipedia.page(\"Business Leaders\")\n",
    "MMA = wikipedia.page(\"Pro MMA\")\n",
    "Phy = wikipedia.page(\"physicist\")\n",
    "Stat = wikipedia.page(\"Statistician\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Boxing is a combat sport in which two people, usually wearing protective gloves, throw punches at each other for a predetermined amount of time in a boxing ring.\\nAmateur boxing is both an Olympic and Commo'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Printing the content of the pages\n",
    "Box.content[:205]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Business acumen (\"Business savvy\" and \"business sense\" are often used as synonyms) is keenness and quickness in understanding and dealing with a \"business situation\" (risks and opportunities) in a manner t'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BL.content[:205]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a list of notable present professional training camps and gyms in Mixed Martial Arts (MMA).Most professional MMA fighters in the UFC, Bellator and other MMA promotions join a professional fight cam'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MMA.content[:205]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Physics (from Ancient Greek: φυσική (ἐπιστήμη), romanized: physikḗ (epistḗmē), lit. 'knowledge of nature', from φύσις phýsis 'nature') is the natural science that studies matter, its motion and behavior th\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Phy.content[:205]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A statistician is a person who works with theoretical or applied statistics. The profession exists in both the private and public sectors. It is common to combine statistical knowledge with expertise in ot'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Stat.content[:205]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box \t 10595 \n",
      "BL\t 1111 \n",
      "MMA \t 252 \n",
      "Phy \t 5675\n"
     ]
    }
   ],
   "source": [
    "#Number of words present in each articles\n",
    "\n",
    "print(\"Box \\t\", len(Box.content.split()), \"\\n\"\n",
    "      \"BL\\t\", len(BL.content.split()), \"\\n\"\n",
    "      \"MMA \\t\", len(MMA.content.split()), \"\\n\"\n",
    "      \"Phy \\t\", len(Phy.content.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "      W1 W2 W3 W4 W5\n",
    "\n",
    "ML = (2, 5, 0, 0, 10)\n",
    "AI = (8, 22, 0, 0, 38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "Box = np.array([2, 5, 0, 0, 10])\n",
    "MMA = np.array([8, 22, 0, 0, 38])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "Phy = np.array([2, 5, 0, 0, 10])\n",
    "Stat = np.array([8, 22, 0, 0, 38])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.301651610693426"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "euclidean_distance(Box, MMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.301651610693426"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "euclidean_distance(Phy,Stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9981848973292723"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(Phy, Stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating count vectors\n",
    "# Use count vectorizer to create a vector of word count\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'content'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-b8bc39a73b92>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mBox\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mBL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mStat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMMA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mPhy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'content'"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "X = np.array(cv.fit_transform([Box.content,BL.content,Stat.content, MMA.content,Phy.content]).toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Creating count vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'content'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-92-12e65542d084>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mBox\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMMA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mStat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPhy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mBL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'content'"
     ]
    }
   ],
   "source": [
    "#Use count vectorizer to create a vector of word count\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer()\n",
    "X = np.array(cv.fit_transform([Box.content, MMA.content, Stat.content, Phy.content,BL.content]).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(<bound method CountVectorizer.fit_transform of CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)>, dtype=object)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Calculating the distance among the articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-ed756e5df476>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Euclidien distances between ML and Rest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Euclidean distance between ML-AI: \\t\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meuclidean_distance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Euclidean distance between ML-Soccer: \\t\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meuclidean_distance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Euclidean distance between ML-Tennis: \\t\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meuclidean_distance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "#Euclidien distances between ML and Rest\n",
    "\n",
    "print(\"Euclidean distance between ML-AI: \\t\", euclidean_distance(X[0],X[1]))\n",
    "print(\"Euclidean distance between ML-Soccer: \\t\", euclidean_distance(X[0],X[2]))\n",
    "print(\"Euclidean distance between ML-Tennis: \\t\", euclidean_distance(X[0],X[3]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean distance between AI-Tennis: \t 644.1513797237417\n"
     ]
    }
   ],
   "source": [
    "print(\"Euclidean distance between AI-Tennis: \\t\", euclidean_distance(X[1],X[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean distance between AI-ML: \t 456.7307740890688\n",
      "Euclidean distance between AI-Soccer: \t 502.6927491022722\n",
      "Euclidean distance between AI-Tennis: \t 644.1513797237417\n"
     ]
    }
   ],
   "source": [
    "#Euclidien distances between ML and Rest\n",
    "\n",
    "print(\"Euclidean distance between AI-ML: \\t\", euclidean_distance(X[0],X[1]))\n",
    "print(\"Euclidean distance between AI-Soccer: \\t\", euclidean_distance(X[1],X[2]))\n",
    "print(\"Euclidean distance between AI-Tennis: \\t\", euclidean_distance(X[1],X[3]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity\n",
      "ML - AI \t 0.8830074014780043 \n",
      " ML - Soccer \t 0.7926233557280901 \n",
      " ML - Tennis \t 0.8073111478120881 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Cosine similarity between ML and Rest\n",
    "\n",
    "print(\"Cosine Similarity\")\n",
    "print(\"ML - AI \\t\", cosine_similarity(X[0],X[1]), \"\\n\",\n",
    "     \"ML - Soccer \\t\", cosine_similarity(X[0],X[2]), \"\\n\",\n",
    "     \"ML - Tennis \\t\", cosine_similarity(X[0],X[3]), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Categorizing a Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here's an ML tweet\n",
    "\n",
    "ml_tweet = \"New research release: overcoming many of Reinforcement Learning's limitations with Evolution Strategies.\"\n",
    "x = np.array(cv.transform([ml_tweet]).toarray())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean distance\n",
      "tweet - ML \t 611.3885834720828 \n",
      "tweet - AI \t 895.1865727321875 \n",
      "tweet - soccer \t 758.5004943966748 \n",
      "tweet - tennis \t 1201.5073865773777\n"
     ]
    }
   ],
   "source": [
    "#Euclindean Distances\n",
    "print(\"Euclidean distance\")\n",
    "\n",
    "print(\"tweet - ML \\t\", euclidean_distance(x[0], X[0]), \"\\n\"\n",
    "      \"tweet - AI \\t\", euclidean_distance(x[0], X[1]), \"\\n\"\n",
    "      \"tweet - soccer \\t\", euclidean_distance(x[0], X[2]), \"\\n\"\n",
    "      \"tweet - tennis \\t\", euclidean_distance(x[0], X[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cosine Similarities\n",
    "\n",
    "print(\"Cosine Similarity\")\n",
    "\n",
    "print(\"tweet - ML \\t\", cosine_similarity(x, X[0]), \"\\n\"\n",
    "      \"tweet - AI \\t\", cosine_similarity(x, X[1]), \"\\n\"\n",
    "      \"tweet - soccer \\t\", cosine_similarity(x, X[2]), \"\\n\"\n",
    "      \"tweet - tennis \\t\", cosine_similarity(x, X[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A soccer tweet, by Manchester United\n",
    "\n",
    "so_tweet = \"#LegendsDownUnder The Reds are out for the warm up at the @nibStadium. Not long now until kick-off in Perth.\"\n",
    "x2 = np.array(cv.transform([so_tweet]).toarray())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Euclidean Distance\n",
    "\n",
    "print(\"tweet - ML \\t\", euclidean_distance(x2, X[0]), \"\\n\"\n",
    "      \"tweet - AI \\t\", euclidean_distance(x2, X[1]), \"\\n\"\n",
    "      \"tweet - soccer \\t\", euclidean_distance(x2, X[2]), \"\\n\"\n",
    "      \"tweet - tennis \\t\", euclidean_distance(x2, X[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cosine Similarity\n",
    "\n",
    "print(\"tweet - ML \\t\", cosine_similarity(x2, X[0]), \"\\n\"\n",
    "      \"tweet - AI \\t\", cosine_similarity(x2, X[1]), \"\\n\"\n",
    "      \"tweet - soccer \\t\", cosine_similarity(x2, X[2]), \"\\n\"\n",
    "      \"tweet - tennis \\t\", cosine_similarity(x2, X[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Reference:* https://cmry.github.io/notes/euclidean-v-cosine"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
